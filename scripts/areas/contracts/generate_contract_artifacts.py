#!/usr/bin/env python3
# Purpose: script interface entrypoint.
# Inputs: command-line args and repository files/env as documented by caller.
# Outputs: exit status and deterministic stdout/stderr or generated artifacts.
import json
import subprocess
from pathlib import Path

ROOT = Path(__file__).resolve().parents[3]
contracts = ROOT / "docs" / "contracts"
out_gen = ROOT / "docs" / "_generated" / "contracts"
out_gen.mkdir(parents=True, exist_ok=True)

error_codes = json.loads((contracts / "ERROR_CODES.json").read_text())["codes"]
metrics = json.loads((contracts / "METRICS.json").read_text())["metrics"]
trace_spans = json.loads((contracts / "TRACE_SPANS.json").read_text())["spans"]
endpoints = json.loads((contracts / "ENDPOINTS.json").read_text())["endpoints"]
chart_keys = json.loads((contracts / "CHART_VALUES.json").read_text())["top_level_keys"]
config_keys = json.loads((contracts / "CONFIG_KEYS.json").read_text())["env_keys"]
artifact_schema = json.loads((contracts / "artifacts" / "ARTIFACT_SCHEMA.json").read_text())
policy_schema = json.loads((contracts / "POLICY_SCHEMA.json").read_text())
qc_schema = json.loads((contracts / "QC_SCHEMA.json").read_text())
normalized_schema = json.loads((contracts / "NORMALIZED_FORMAT_SCHEMA.json").read_text())
diff_schema = json.loads((contracts / "DIFF_SCHEMA.json").read_text())
sharding_schema = json.loads((contracts / "SHARDING_SCHEMA.json").read_text())
cursor_schema = json.loads((contracts / "CURSOR_SCHEMA.json").read_text())
error_schema = json.loads((contracts / "ERROR_SCHEMA.json").read_text())
error_status_map = json.loads((contracts / "ERROR_STATUS_MAP.json").read_text())


def write_reference_contract_doc(path: Path, title: str, contracts_body: str, examples_body: str) -> None:
    path.write_text(
        "\n".join(
            [
                f"# {title}",
                "",
                "- Owner: `docs-governance`",
                "",
                "## What",
                "",
                f"Defines the `{title}` registry contract.",
                "",
                "## Why",
                "",
                "Prevents drift between SSOT JSON, generated code, and operational consumers.",
                "",
                "## Scope",
                "",
                "Applies to producers and consumers of this registry.",
                "",
                "## Non-goals",
                "",
                "Does not define implementation internals outside this contract surface.",
                "",
                "## Contracts",
                "",
                contracts_body,
                "",
                "## Failure modes",
                "",
                "Invalid or drifted registry content is rejected by contract checks and CI gates.",
                "",
                "## Examples",
                "",
                examples_body,
                "",
                "## How to verify",
                "",
                "```bash",
                "$ make ssot-check",
                "$ make docs-freeze",
                "```",
                "",
                "Expected output: both commands exit status 0 and print contract generation/check success.",
                "",
                "## See also",
                "",
                "- [Contracts Index](contracts-index.md)",
                "- [SSOT Workflow](ssot-workflow.md)",
                "- [Terms Glossary](../_style/terms-glossary.md)",
                "",
            ]
        )
    )

# rust generated core error-code enum + constants
core_generated_dir = ROOT / "crates" / "bijux-atlas-core" / "src" / "generated"
core_generated_dir.mkdir(parents=True, exist_ok=True)
(core_generated_dir / "mod.rs").write_text("pub mod error_codes;\n")

core_rust_path = core_generated_dir / "error_codes.rs"
core_rust = [
    "// @generated by scripts/areas/contracts/generate_contract_artifacts.py",
    "use serde::{Deserialize, Serialize};",
    "",
    "#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]",
    "#[non_exhaustive]",
    "pub enum ErrorCode {",
]
for code in error_codes:
    core_rust.append(f"    {code},")
core_rust.extend(
    [
        "}",
        "",
        "impl ErrorCode {",
        "    #[must_use]",
        "    pub const fn as_str(self) -> &'static str {",
        "        match self {",
    ]
)
for code in error_codes:
    core_rust.append(f'            Self::{code} => "{code}",')
core_rust.extend(
    [
        "        }",
        "    }",
        "",
        "    pub fn parse(value: &str) -> Option<Self> {",
        "        match value {",
    ]
)
for code in error_codes:
    core_rust.append(f'            "{code}" => Some(Self::{code}),')
core_rust.extend(
    [
        "            _ => None,",
        "        }",
        "    }",
        "}",
        "",
        "#[allow(dead_code)]",
        "pub const ERROR_CODES: &[&str] = &[",
    ]
)
for code in error_codes:
    core_rust.append(f'    "{code}",')
core_rust.append("];\n")
core_rust_path.write_text("\n".join(core_rust))

# rust generated API constants
rust_path = ROOT / "crates" / "bijux-atlas-api" / "src" / "generated" / "error_codes.rs"
rust_path.parent.mkdir(parents=True, exist_ok=True)
rust = [
    "// @generated by scripts/areas/contracts/generate_contract_artifacts.py",
    "pub const API_ERROR_CODES: &[&str] = &[",
]
for code in error_codes:
    rust.append(f'    "{code}",')
rust.extend(
    [
        "];",
        "",
        "#[allow(dead_code)]",
        "pub type ApiErrorCode = bijux_atlas_core::ErrorCode;",
        "",
        "#[allow(dead_code)]",
        "pub fn parse_error_code(value: &str) -> Option<ApiErrorCode> {",
        "    ApiErrorCode::parse(value)",
        "}",
        "",
    ]
)
rust_path.write_text("\n".join(rust))

# rust generated metrics + trace span constants
server_gen_dir = ROOT / "crates" / "bijux-atlas-server" / "src" / "telemetry" / "generated"
server_gen_dir.mkdir(parents=True, exist_ok=True)
(server_gen_dir / "mod.rs").write_text(
    "// @generated by scripts/areas/contracts/generate_contract_artifacts.py\n"
    "pub mod metrics_contract;\n"
    "pub mod trace_spans_contract;\n"
)

metrics_rs = [
    "// @generated by scripts/areas/contracts/generate_contract_artifacts.py",
    "#[allow(dead_code)]",
    "pub const CONTRACT_METRIC_NAMES: &[&str] = &[",
]
for metric in metrics:
    metrics_rs.append(f'    "{metric["name"]}",')
metrics_rs.append("];")
metrics_rs.append("")
metrics_rs.append("#[allow(dead_code)]")
metrics_rs.append("pub const CONTRACT_METRIC_LABELS: &[(&str, &[&str])] = &[")
for metric in metrics:
    metrics_rs.append("    (")
    metrics_rs.append(f'        "{metric["name"]}",')
    labels = ", ".join(f'"{x}"' for x in metric["labels"])
    metrics_rs.append(f"        &[{labels}],")
    metrics_rs.append("    ),")
metrics_rs.append("];\n")
(server_gen_dir / "metrics_contract.rs").write_text("\n".join(metrics_rs))

spans_rs = [
    "// @generated by scripts/areas/contracts/generate_contract_artifacts.py",
    "#[allow(dead_code)]",
    "pub const CONTRACT_TRACE_SPAN_NAMES: &[&str] = &[",
]
for span in trace_spans:
    spans_rs.append(f'    "{span["name"]}",')
spans_rs.append("];")
spans_rs.append("")
spans_rs.append("#[allow(dead_code)]")
spans_rs.append("pub const CONTRACT_TRACE_SPAN_ATTRIBUTES: &[(&str, &[&str])] = &[")
for span in trace_spans:
    spans_rs.append("    (")
    spans_rs.append(f'        "{span["name"]}",')
    attrs = ", ".join(f'"{x}"' for x in span["required_attributes"])
    spans_rs.append(f"        &[{attrs}],")
    spans_rs.append("    ),")
spans_rs.append("];\n")
(server_gen_dir / "trace_spans_contract.rs").write_text("\n".join(spans_rs))

for rust_file in (
    core_generated_dir / "mod.rs",
    core_rust_path,
    rust_path,
    server_gen_dir / "mod.rs",
    server_gen_dir / "metrics_contract.rs",
    server_gen_dir / "trace_spans_contract.rs",
):
    subprocess.run(["rustfmt", str(rust_file)], check=True)

# markdown artifacts
(out_gen / "ERROR_CODES.md").write_text(
    "# Error Codes (Generated)\n\n" + "\n".join(f"- `{c}`" for c in error_codes) + "\n"
)
(out_gen / "METRICS.md").write_text(
    "# Metrics (Generated)\n\n"
    + "\n".join(
        f"- `{m['name']}` labels: {', '.join(m['labels'])}" for m in metrics
    )
    + "\n"
)
(out_gen / "ENDPOINTS.md").write_text(
    "# Endpoints (Generated)\n\n"
    + "\n".join(
        f"- `{e['method']} {e['path']}` telemetry: `{e['telemetry_class']}`"
        for e in endpoints
    )
    + "\n"
)
(out_gen / "CHART_VALUES.md").write_text(
    "# Chart Values Keys (Generated)\n\n"
    + "\n".join(f"- `{k}`" for k in chart_keys)
    + "\n"
)
(out_gen / "TRACE_SPANS.md").write_text(
    "# Trace Spans (Generated)\n\n"
    + "\n".join(
        f"- `{s['name']}` attrs: {', '.join(s['required_attributes'])}" for s in trace_spans
    )
    + "\n"
)
(out_gen / "CONFIG_KEYS.md").write_text(
    "# Config Keys (Generated)\n\n"
    + "\n".join(f"- `{k}`" for k in config_keys)
    + "\n"
)
(out_gen / "ARTIFACT_SCHEMA.md").write_text(
    "# Artifact Schema (Generated)\n\n```json\n"
    + json.dumps(artifact_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "POLICY_SCHEMA.md").write_text(
    "# Policy Schema (Generated)\n\n```json\n"
    + json.dumps(policy_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "QC_SCHEMA.md").write_text(
    "# QC Schema (Generated)\n\n```json\n"
    + json.dumps(qc_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "NORMALIZED_FORMAT_SCHEMA.md").write_text(
    "# Normalized Format Schema (Generated)\n\n```json\n"
    + json.dumps(normalized_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "DIFF_SCHEMA.md").write_text(
    "# Diff Schema (Generated)\n\n```json\n"
    + json.dumps(diff_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "SHARDING_SCHEMA.md").write_text(
    "# Sharding Schema (Generated)\n\n```json\n"
    + json.dumps(sharding_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "CURSOR_SCHEMA.md").write_text(
    "# Cursor Schema (Generated)\n\n```json\n"
    + json.dumps(cursor_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "ERROR_SCHEMA.md").write_text(
    "# Error Schema (Generated)\n\n```json\n"
    + json.dumps(error_schema, indent=2, sort_keys=True)
    + "\n```\n"
)
(out_gen / "ERROR_STATUS_MAP.md").write_text(
    "# Error Status Map (Generated)\n\n```json\n"
    + json.dumps(error_status_map, indent=2, sort_keys=True)
    + "\n```\n"
)

# canonical generated contract docs under docs/contracts/
error_contract_lines = [
    f"- `{c}`: stable machine error code for API and CLI contract surfaces." for c in error_codes
]
error_examples = []
for code in error_codes:
    error_examples.extend(
        [
            f"### `{code}`",
            "```json",
            json.dumps(
                {
                    "error": {
                        "code": code,
                        "message": f"{code} error",
                        "details": {"field": "example"},
                    }
                },
                indent=2,
                sort_keys=True,
            ),
            "```",
            "",
        ]
    )
write_reference_contract_doc(
    contracts / "errors.md",
    "Error Codes Contract",
    "\n".join(error_contract_lines),
    "\n".join(error_examples).rstrip(),
)

metrics_contract_lines = [
    f"- `{m['name']}` labels: {', '.join(m['labels'])}" for m in metrics
]
write_reference_contract_doc(
    contracts / "metrics.md",
    "Metrics Contract",
    "\n".join(metrics_contract_lines)
    + "\n\nLabel cardinality rules:\n"
    + "- User-controlled values must not be used as metric labels.\n"
    + "- Allowed dynamic labels are constrained by `ops/obs/contract/metrics-contract.json`.",
    "```json\n"
    + json.dumps(
        {
            "metric": metrics[0]["name"] if metrics else "atlas_requests_total",
            "labels": metrics[0]["labels"] if metrics else ["route", "status"],
        },
        indent=2,
        sort_keys=True,
    )
    + "\n```",
)

span_lines = [
    f"- `{s['name']}` required attributes: {', '.join(s['required_attributes'])}" for s in trace_spans
]
write_reference_contract_doc(
    contracts / "tracing.md",
    "Trace Spans Contract",
    "\n".join(span_lines),
    "```json\n"
    + json.dumps(
        {
            "span": trace_spans[0]["name"] if trace_spans else "request",
            "required_attributes": (
                trace_spans[0]["required_attributes"] if trace_spans else ["request_id"]
            ),
        },
        indent=2,
        sort_keys=True,
    )
    + "\n```",
)

endpoint_lines = [
    f"- `{e['method']} {e['path']}` telemetry class: `{e['telemetry_class']}`" for e in endpoints
]
write_reference_contract_doc(
    contracts / "endpoints.md",
    "Endpoints Contract",
    "\n".join(endpoint_lines)
    + "\n\nOpenAPI reference:\n- `configs/openapi/v1/openapi.yaml`",
    "```bash\n$ ./scripts/areas/internal/openapi-generate.sh\n```\n\nExpected output: generator succeeds and endpoint drift checks pass.",
)

config_key_lines = [f"- `{k}`" for k in config_keys]
write_reference_contract_doc(
    contracts / "config-keys.md",
    "Config Keys Contract",
    "\n".join(config_key_lines) + "\n\nPolicy schema reference: `docs/contracts/POLICY_SCHEMA.json`",
    "```bash\n$ ./scripts/areas/contracts/check_config_keys_contract.py\n```\n\nExpected output: \"config key contract check passed\".",
)

chart_value_lines = [f"- `{k}`" for k in chart_keys]
write_reference_contract_doc(
    contracts / "chart-values.md",
    "Chart Values Contract",
    "\n".join(chart_value_lines),
    "```yaml\n# default profile\nserver:\n  cachedOnlyMode: false\n  logJson: true\n\n# offline profile\noffline:\n  enabled: true\nserver:\n  cachedOnlyMode: true\n```\n\nExpected output: values keys validate against `CHART_VALUES.json`.",
)

# generated compatibility artifact for observability gate
obs_metrics_path = ROOT / "ops" / "obs" / "contract" / "metrics-contract.json"
user_controlled_labels = [
    "request_id",
    "trace_id",
    "dataset_id",
    "gene_id",
    "tx_id",
    "path",
    "query",
    "raw_path",
]


def _metric_spec(metric: dict) -> dict:
    name = metric["name"]
    labels = metric["labels"]
    metric_type = "gauge"
    if name.endswith("_total"):
        metric_type = "counter"
    elif "_p95_" in name:
        metric_type = "histogram"

    unit = "count"
    if "seconds" in name:
        unit = "seconds"
    elif "bytes" in name:
        unit = "bytes"
    elif name.endswith("_ns"):
        unit = "nanoseconds"

    relevant = any(
        token in name
        for token in (
            "latency",
            "errors_total",
            "shed",
            "overload",
            "requests_total",
            "store_breaker",
        )
    )
    slos = []
    if relevant:
        if "latency" in name:
            slos.append("latency")
        if any(token in name for token in ("errors", "shed", "requests_total", "overload")):
            slos.append("availability")
        if "store" in name:
            slos.append("dependency")

    criticality = "tier-1" if relevant else "tier-2"
    if name.startswith("atlas_"):
        criticality = "tier-0"

    return {
        "type": metric_type,
        "unit": unit,
        "cardinality_budget": {"max_series": 512, "max_new_series_per_hour": 128},
        "required_labels": labels,
        "forbidden_labels": [label for label in user_controlled_labels if label not in labels],
        "example_series": f'{name}{{'
        + ",".join(f'{label}="example"' for label in labels)
        + "}} 1",
        "semantic": {
            "what_it_measures": f"{name} contract metric",
            "on_break_action": "check exporter, contract, and runtime telemetry path",
        },
        "owner": {
            "crate": "bijux-atlas-server",
            "module": "src/telemetry/metrics_endpoint.rs",
        },
        "slo_relevance": {"relevant": relevant, "slos": slos},
        "criticality": criticality,
    }


existing_obs_payload = {}
if obs_metrics_path.exists():
    try:
        existing_obs_payload = json.loads(obs_metrics_path.read_text())
    except json.JSONDecodeError:
        existing_obs_payload = {}
existing_specs = existing_obs_payload.get("required_metric_specs", {})

obs_payload = {
    "schema_version": 1,
    "required_metrics": {m["name"]: m["labels"] for m in metrics},
    "required_metric_specs": {
        m["name"]: existing_specs.get(m["name"], _metric_spec(m)) for m in metrics
    },
    "required_spans": existing_obs_payload.get(
        "required_spans", [s["name"] for s in trace_spans]
    ),
    "required_log_fields": existing_obs_payload.get(
        "required_log_fields", ["request_id", "dataset"]
    ),
    "allowed_dynamic_labels": existing_obs_payload.get(
        "allowed_dynamic_labels", ["route", "status", "query_type", "stage", "code"]
    ),
}
if "forbidden_labels" in existing_obs_payload:
    obs_payload["forbidden_labels"] = existing_obs_payload["forbidden_labels"]
obs_metrics_path.write_text(json.dumps(obs_payload, indent=2, sort_keys=True) + "\n")

print("contract artifacts generated")
